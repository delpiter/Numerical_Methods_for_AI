{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dfde07b5-f3c8-401d-9d53-311afa18d46c",
   "metadata": {},
   "source": [
    "## Utilities for Exam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75730321-a15a-43e8-8f6b-6f3ff081f265",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sympy as sim\n",
    "import scipy as sp\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import SolveTriangular as st"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e20d7a75-aea5-477c-9ee1-84a85b4cf526",
   "metadata": {},
   "source": [
    "### Matrix Conditions\n",
    "- The following blocks will display some function to check matrixes constraints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef5c8d68-813f-496a-8585-f3207de5ce30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if a matrix is positively defined\n",
    "def is_positively_defined(A):\n",
    "    return np.all(np.linalg.eigvals(A) > 0)\n",
    "\n",
    "# Check if a matri is symmetric\n",
    "def is_symmetric(A):\n",
    "    return np.all(A==A.T)\n",
    "\n",
    "# Check if the matrix has max rank\n",
    "def has_max_rank(A):\n",
    "    return A.shape[0]==np.linalg.matrix_rank(A)\n",
    "\n",
    "# Check if its a square matrix\n",
    "def is_square(A):\n",
    "    return A.shape[0]==A.shape[1]\n",
    "\n",
    "# Check if the matrix is well or ill conditioned\n",
    "\"\"\"\n",
    "Returns:\n",
    "- 1 if the matrix is well conditioned\n",
    "- 0 if is averagely poorly ill\n",
    "- -1 if is ill conditioned\n",
    "\"\"\"\n",
    "def matrix_condition(A):\n",
    "    cond=np.linalg.cond(A)\n",
    "    if cond < 10**2:\n",
    "        return 1\n",
    "    elif cond>=10**2 and cond<=10**3:\n",
    "        return 0\n",
    "    else:\n",
    "        return -1\n",
    "\n",
    "# Check if the singularity of a matrix\n",
    "def is_not_singular(A):\n",
    "    return np.linalg.det(A)!=0\n",
    "    \n",
    "# Check if the matrix is dense\n",
    "def density_Percentage(A):\n",
    "    return np.count_nonzero(A)/(A.shape[0]*A.shape[1])\n",
    "\n",
    "# Check if the matrix is strictly diagonally dominant\n",
    "def is_diagonally_dominant(A):\n",
    "    abs_A = np.abs(A)\n",
    "    return np.all(2*np.diag(abs_A) > np.sum(abs_A, axis=1)) #|Aii| ≥ ∑j≠i |Aij|  =>  2|Aii| ≥ ∑j |Aij|.\n",
    "\n",
    "# A (square) matrix is small if its dimension is in range of 10<x<100\n",
    "# Its big if is in range of 300<x<500"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "216c3557-63cd-4e27-9d84-ed964e48d64c",
   "metadata": {},
   "source": [
    "## Roots of a Function\n",
    "---\n",
    "> Metodi:\n",
    "\n",
    "1. Bisection.\n",
    "2. Regula Falsi\n",
    "3. Metodo delle Corde\n",
    "4. Metodo delle Secanti\n",
    "5. Newton, Newton Modified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cfa57a31-d950-4cc8-9961-5a22e3ce418b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def order_valuation(xk,iterazioni):\n",
    "     #Vedi dispensa allegata per la spiegazione\n",
    "\n",
    "    k=iterazioni-4\n",
    "    p=np.log(abs(xk[k+2]-xk[k+3])/abs(xk[k+1]-xk[k+2]))/np.log(abs(xk[k+1]-xk[k+2])/abs(xk[k]-xk[k+1]));\n",
    "    \n",
    "    ordine=p\n",
    "    return ordine\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a15aceb9-1a44-49df-9e38-22dc1e05c0de",
   "metadata": {},
   "source": [
    "### Bisection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bac7d78-bf92-4cc5-be78-62a0578c9d06",
   "metadata": {},
   "source": [
    "> Key Operation:\n",
    "\n",
    "$$x_{k+1}=a_{k} +\\displaystyle\\frac{b_k-a_k}{2}$$\n",
    "If $f(a)*f(x_{k+1})<0$\n",
    "- $b=x_{k+1}$\n",
    "\n",
    "If $f(a)*f(x_{k+1})>0$\n",
    "- $a=x_{k+1}$\n",
    "\n",
    "> Ordine di Convergenza Lineare con $p=1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8e5e16b-784d-44bc-92bb-fa54cb03a555",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bisection(f, a, b, tolx):\n",
    "    fa=f(a)\n",
    "    fb=f(b)\n",
    "    \n",
    "    if fa*fb >= 0:\n",
    "        print(\"Failed to apply method\")\n",
    "        return None, None, None\n",
    "\n",
    "    it = 0\n",
    "    v_xk = []\n",
    "\n",
    "    while abs(b-a)> tolx:\n",
    "        xk = a+(b-a)/2 # key operation\n",
    "        v_xk.append(xk)\n",
    "        it+=1\n",
    "        fxk=f(xk)\n",
    "        if fxk==0:\n",
    "            return xk, it, v_xk\n",
    "        \n",
    "        if fa*fxk < 0: # la radice si trova nell'intervallo [a, xk]\n",
    "            b = xk\n",
    "            fb=fxk\n",
    "        elif fxk*fb < 0: # intervallo [xk, b]\n",
    "            a=xk\n",
    "            fa=fxk\n",
    "    return xk, it, v_xk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0862a6c6-cbb9-4d30-a8cf-0dabca8e7ceb",
   "metadata": {},
   "source": [
    "### Regula Falsi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3691031a-ffb0-4968-8d8f-0c9f7f554da5",
   "metadata": {},
   "source": [
    "Algoritmo pressoché uguale alla bisezione:\n",
    "\n",
    "> Key Operation\n",
    "\n",
    "$$x_{k+1}=a_{k}-f(a_{k})\\cdot \\displaystyle{\\frac{b_{k}-a_{k}}{f(b_{k})-f(a_{k})}}$$\n",
    "> Perchè?\n",
    "\n",
    "Il concetto sarebbe quello di **considerare** anche i **valori che la funzione assume negli estremi dell'intervallo**.\n",
    "- Si considera come *nuova approssimazione* della soluzione la retta passante per $(a,f(a)), (b,f(b))$\n",
    "\n",
    "> Ordine di Convergenza Superlineare con $p<1.5$ (generalmente)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1d431db-5726-4b6d-9384-edc2b3fffc6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def falses(f, a, b, tolx, tolf, maxit):\n",
    "    fa=f(a)\n",
    "    fb=f(b)\n",
    "\n",
    "    if fa*fb >= 0:\n",
    "        print(\"Failed to apply method\")\n",
    "        return None, None, None\n",
    "    \n",
    "    it = 0\n",
    "    v_xk=[]\n",
    "    fxk=100\n",
    "    error=100 # difference between 2 consecutive calculation\n",
    "    xprec=a\n",
    "    \n",
    "    while it<maxit and abs(fxk)> tolf and error > tolx:\n",
    "        xk = a-fa*(b-a)/(fb-fa) # key operation\n",
    "        v_xk.append(xk)\n",
    "        it+=1\n",
    "        fxk=f(xk)\n",
    "        if fxk==0:\n",
    "            return xk, it, v_xk\n",
    "\n",
    "        if fa*fxk < 0: # la radice si trova nell'intervallo [a, xk]\n",
    "            b = xk\n",
    "            fb=fxk\n",
    "        elif fxk*fb < 0: # intervallo [xk, b]\n",
    "            a=xk\n",
    "            fa=fxk\n",
    "        if xk!=0:\n",
    "            error=abs(xk-xprec)/abs(xk)\n",
    "        else:\n",
    "            error=abs(xk-xprec)\n",
    "        xprec=xk\n",
    "    return xk, it, v_xk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "831ee73b-b2fa-4c82-8456-2ea2353ca900",
   "metadata": {},
   "source": [
    "### Linearizzazione\n",
    "> Data $f(x),x_{0},f(x_{0})$: si ***approssima*** la funzione con una retta per $(x_{0},f(x_{0}))$.\n",
    "\n",
    "- $x_{k+1}=x_{k}-\\displaystyle\\frac{f(x_{k})}{m_{k}}$\n",
    "\n",
    "A seconda della scelta di $m_k$ abbiamo metodi diversi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "688fa829-a4ac-4621-9dd3-da8a15dc0dd1",
   "metadata": {},
   "source": [
    "#### Metodo delle Corde\n",
    "> Il metodo assume la forma\n",
    "\n",
    "$$x_{k+1}=x_{k}-\\frac{f(x_{k})}{m}$$\n",
    "- $m$ è dato all'inizio e viene usato per ***tutte le iterazioni***\n",
    "\n",
    "Scelta classica: $m=\\frac{f(b)-f(a)}{b-a}$\n",
    "$$\n",
    "x_{k+1}=x_{k}-\\displaystyle{\\frac{b-a}{f(b)-f(a)}}f(x_{k})\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0bab58aa-9294-4e71-aeb1-54d2e827bacd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def corde(f, x0, coeff_ang, tolx, tolf, nmax):\n",
    "    xk=[] # iterati successivi\n",
    "    it=0\n",
    "    errorex=1+tolx # Inizializziamo gli errori in modo che entri nel while almeno una volta\n",
    "    erroref=1+tolf #\n",
    "\n",
    "    while it<nmax and erroref>=tolf and errorex>=tolx :\n",
    "        fx0=f(x0)       #|\n",
    "        d=fx0/coeff_ang #| Key Operations\n",
    "        x1=x0-d         #|\n",
    "        fx1=f(x1)\n",
    "        erroref=np.abs(fx1)\n",
    "        if x1!=0:\n",
    "            errorex=abs(d)/abs(x1)\n",
    "        else:\n",
    "            errorex=abs(d)\n",
    "        x0=x1\n",
    "        it=it+1\n",
    "        xk.append(x1)\n",
    "    if(it==nmax):\n",
    "        print('Max Iteration Reached')\n",
    "    return x1,it,xk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "669b7b77-a5d9-4d17-a451-af18840d0ea2",
   "metadata": {},
   "source": [
    "#### Metodo delle Secanti\n",
    "> Il seguente metodo richiede **due iterati iniziali**\n",
    "\n",
    "L'**approssimazione** della funzione $f$ nell'intervallo $[x_{k-1},x_{k}]$ è la retta che passa per i punti: $(x_{k-1}),f(x_{k-1}),(x_{k},f(x_{k}))$ con *coefficiente angolare*:\n",
    "$$m_{k}=\\frac{f(x_{k})-f(x_{k-1})}{x_{k}-x_{k-1}}$$\n",
    "\n",
    "> La formula diventa:\n",
    "\n",
    "$$\n",
    "x_{k+1}=x_{k}-f(x_{k}) \\displaystyle{\\frac{x_{k}-x_{k-1}}{f(x_{k})-f(x_{k-1})}}\n",
    "$$\n",
    "\n",
    "La convergenza è ***garantita*** se le approssimazioni $x_{0}$ e $x_{1}$ si scelgono abbastanza **vicine alla soluzione**.\n",
    "\n",
    "> Ordine di Convergenza Superlineare $p=\\frac{1+\\sqrt{ 5 }}{2}\\approx1.618$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1158ad37-e1d1-4b99-9705-dace90bd6e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def secanti(f, x0, x1, tolx, tolf, nmax):\n",
    "    xk=[] # iterati successivi\n",
    "    it=0\n",
    "    errorex=1+tolx # Inizializziamo gli errori in modo che entri nel while almeno una volta\n",
    "    erroref=1+tolf #\n",
    "\n",
    "    while it<nmax and erroref>=tolf and errorex>=tolx :\n",
    "        fx0=f(x0)                 #\n",
    "        fx1=f(x1)                 # Key Operations\n",
    "        d=fx1*((x1-x0)/(fx1-fx0)) #\n",
    "        \n",
    "        x1new=x1-d \n",
    "        \n",
    "        fx1=f(x1new)\n",
    "        \n",
    "        xk.append(x1new)\n",
    "        \n",
    "        if x1new!=0:\n",
    "            errorex=abs(d)/abs(x1new)\n",
    "        else:\n",
    "            errorex=abs(d)\n",
    "            \n",
    "        erroref=abs(fx1)\n",
    "        \n",
    "        x0=x1\n",
    "        x1=x1new\n",
    "        it=it+1\n",
    "    if(it==nmax):\n",
    "        print('Max Iteration Reached')\n",
    "    return x1,it,xk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c37929-3964-49ac-a8c8-63fec4dc0540",
   "metadata": {},
   "source": [
    "#### Newton\n",
    "> Ad ogni passo $k$ si considera la retta passante per il punto $(x_{k},f(x_{k}))$ e *tangente alla curva* $f(x)$.\n",
    "\n",
    "Si determina il nuovo iterato come il punto di incontro tra la **retta** e l'*asse* delle $x$.\n",
    "- $m_k=f'(x_k)$\n",
    "\n",
    "$$\n",
    "x_{k+1}=x_{k}-\\frac{f(x_{k})}{f'(x_{k})}\n",
    "$$\n",
    "\n",
    "> Ordine di convergenza Quadratica con $p=2$\n",
    "\n",
    "A meno che la funzione $f$ abbia una molteplicità nello zero $\\alpha$: $m>1$,\n",
    "- Il metodo di *Newton* non ha più convergenza *Quadratica* ma **Lineare**.\n",
    "\n",
    "Soluzione:\n",
    "- Applicare il metodo di newton modificato:\n",
    "$$x_{k+1}=x_{k}-m \\displaystyle{\\frac{f(x_{k})}{f'(x_{k})}}$$\n",
    "\n",
    "Che si dimostra avere convergenza $p=2$\n",
    "- Dove $m$ è la molteplicità dello zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ce9b3f3-69c6-4c80-acd8-f6b30956b3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def newton(f,d_f,x0,tolx,tolf,nmax):\n",
    "  \n",
    "    xk=[]\n",
    "    \n",
    "    it=0\n",
    "    errorx=1+tolx\n",
    "    errorf=1+tolf\n",
    "    \n",
    "    while it<nmax and errorf>=tolf and errorx >= tolx:\n",
    "        fx0=f(x0)\n",
    "        if abs(d_f(x0))<=np.spacing(1):\n",
    "            print(\"First Derivate = 0 in x0\")\n",
    "            return None, None, None\n",
    "        \n",
    "        d=f_x0/d_f(x0)\n",
    "        x1=x0-d # Key operations\n",
    "        \n",
    "        fx1=f(x1)\n",
    "        errorf=np.abs(fx1)\n",
    "        if x1!=0:\n",
    "            errorx=abs(d)/abs(x1)\n",
    "        else:\n",
    "            errorx=abs(d) \n",
    "        \n",
    "        it=it+1\n",
    "        x0=x1\n",
    "        xk.append(x1)\n",
    "      \n",
    "    if it==nmax:\n",
    "        print('Max Iteration Reached')\n",
    "        \n",
    "    \n",
    "    return x1,it,xk\n",
    "\n",
    "def newton_molteplicity(f,d_f,m,x0,tolx,tolf,nmax):    \n",
    "    xk=[]\n",
    "    \n",
    "    it=0\n",
    "    errorx=1+tolx\n",
    "    errorf=1+tolf\n",
    "    \n",
    "    while it<nmax and errorf>=tolf and errorx >= tolx:\n",
    "        fx0=f(x0)\n",
    "        if abs(d_f(x0))<=np.spacing(1):\n",
    "            print(\"First Derivate = 0 in x0\")\n",
    "            return None, None, None\n",
    "        \n",
    "        d=f_x0/d_f(x0)\n",
    "        x1=x0-m*d # Key operations\n",
    "        \n",
    "        fx1=f(x1)\n",
    "        errorf=np.abs(fx1)\n",
    "        if x1!=0:\n",
    "            errorx=abs(d)/abs(x1)\n",
    "        else:\n",
    "            errorx=abs(d)\n",
    "        \n",
    "        it=it+1\n",
    "        x0=x1\n",
    "        xk.append(x1)\n",
    "      \n",
    "    if it==nmax:\n",
    "        print('Max Iteration Reached')  \n",
    "    return x1,it,xk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eea7609-cab1-4c29-971a-716e68404b3d",
   "metadata": {},
   "source": [
    "## Systems\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac9af05b-2c08-433b-a346-40be9ea410c3",
   "metadata": {},
   "source": [
    "### Non-Linear System Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71dbf7f8-ad36-4f92-b9d0-9039588ce278",
   "metadata": {},
   "source": [
    "#### Newton Rapshon\n",
    "> Il metodo consiste nel trasformare la **funzione non lineare** nel corrispondente *sviluppo di taylor*.\n",
    "\n",
    "Ricavando il sistema:\n",
    "$$\n",
    "\\begin{cases}\n",
    "\\displaystyle 0 = f_1\\left(x_1^{(k)}, x_2^{(k)}\\right) + \\frac{\\partial f_1}{\\partial x_1}\\left(x_1^{(k)}, x_2^{(k)}\\right)(x_1 - x_1^{(k)}) + \\frac{\\partial f_1}{\\partial x_2}\\left(x_1^{(k)}, x_2^{(k)}\\right)(x_2 - x_2^{(k)}) \\\\\n",
    "\\displaystyle 0 = f_2\\left(x_1^{(k)}, x_2^{(k)}\\right) + \\frac{\\partial f_2}{\\partial x_1}\\left(x_1^{(k)}, x_2^{(k)}\\right)(x_1 - x_1^{(k)}) + \\frac{\\partial f_2}{\\partial x_2}\\left(x_1^{(k)}, x_2^{(k)}\\right)(x_2 - x_2^{(k)})\n",
    "\\end{cases}\n",
    "$$\n",
    "Che espresso in forma matriciale:\n",
    "$$\n",
    "\\begin{array}\n",
    "\\ 0=F(X_{k})+J(X_{k})(X-X_{k}) \\\\\n",
    "J(X_{k})(X-X_{k})=-F(X_{k}) \\\\\n",
    "\\end{array}\n",
    "$$\n",
    "Sotto l'ipotesi che la Jacobiana sia invertibile:\n",
    "- $\\cancel{ J^{-1}(X_{k})J(X_{k}) }(X-X_{k})=-J^{-1}(X_{k})F(X_{k})$\n",
    "\n",
    "Possiamo notare che $-J^{-1}(X_{k})F(X_{k})$ è la soluzione del sistema lineare\n",
    "$$J(X_{k})s_{k}=-F(X_{k})$$\n",
    "\n",
    "> Schematizzazione dell'algoritmo:\n",
    "1. Valutare $J(X_{k-1})$\n",
    "2. Risolvere il sistema lineare $J(X_{k-1})s_{k-1}=-F(X_{k-1})$\n",
    "3. Porre $X_k=X_{k-1}+s_{k-1}$\n",
    "\n",
    "> Convergenza\n",
    "\n",
    "Metodo a convergenza **Locale** e ordine di convergenza **Quadratica**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7cf43600-33bc-4d7d-91c2-403288b1deed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def newton_rapshon(init_guess,f,J,tolx,tolf,nmax):\n",
    "    X=np.array(init_guess, dtype=float)\n",
    "    \n",
    "    it=0\n",
    "    errorf=1+tolf\n",
    "    errorx=1+tolx\n",
    "    error=[]\n",
    "\n",
    "    while it<nmax and errorf>=tolf and errorx>=tolx:\n",
    "        jx=J(X[0],X[1])\n",
    "        \n",
    "        if np.linalg.det(jx)==0:\n",
    "            print(\"J-Matrix does not have max rank\")\n",
    "            return None,None,None\n",
    "        \n",
    "        fx=np.array(f(X[0],X[1]))\n",
    "        fx=fx.squeeze()\n",
    "        \n",
    "        s=np.linalg.solve(jx,-fx)\n",
    "\n",
    "        Xnew=X+s\n",
    "        XnNorm=np.linalg.norm(Xnew,1)\n",
    "\n",
    "        if XnNorm!=0:\n",
    "            errorx=np.linalg.norm(s,1)/XnNorm\n",
    "        else:\n",
    "            errorx=np.linalg.norm(s,1)\n",
    "\n",
    "        error.append(errorx)\n",
    "        fnew=f(Xnew[0],Xnew[1])\n",
    "        errorf=np.linalg.norm(fnew.squeeze(),1)\n",
    "\n",
    "        X=Xnew\n",
    "        it=it+1\n",
    "    return X,it,error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68697b9a-5bd3-4f5a-95d3-eb6aa3e2f503",
   "metadata": {},
   "source": [
    "#### Newton Rapshon Corde\n",
    "> Concetto chiave\n",
    "- La Jacobiana viene ***valutata solo la prima volta*** e si usa sempre lo *stesso valore*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "810ce079-9389-4143-b62e-0e07522be2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def newton_rapshon_corde(init_guess,f,J,tolx,tolf,nmax):\n",
    "    X=np.array(init_guess)\n",
    "    \n",
    "    it=0\n",
    "    errorf=1+tolf\n",
    "    errorx=1+tolx\n",
    "    error=[]\n",
    "    \n",
    "    jx=J(X[0],X[1]) # calculate jx only one time\n",
    "    \n",
    "    if np.linalg.det(jx)==0:\n",
    "        print(\"J-Matrix does not have max rank\")\n",
    "        return None,None,None\n",
    "\n",
    "    while it<nmax and errorf>=tolf and errorx>=tolx:\n",
    "        fx=np.array(f(X[0],X[1]))\n",
    "        fx=fx.squeeze()\n",
    "        \n",
    "        s=np.linalg.solve(jx,-fx)\n",
    "\n",
    "        Xnew=X+s\n",
    "        XnNorm=np.linalg.norm(Xnew,1)\n",
    "\n",
    "        if XnNorm!=0:\n",
    "            errorx=np.linalg.norm(s,1)/XnNorm\n",
    "        else:\n",
    "            errorx=np.linalg.norm(s,1)\n",
    "        error.append(errorx)\n",
    "        fnew=f(Xnew[0],Xnew[1])\n",
    "        errorf=np.linalg.norm(fnew.squeeze(),1)\n",
    "\n",
    "        X=Xnew\n",
    "        it=it+1\n",
    "    return X,it,error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fab6e1e-a84c-4fd3-8a97-69fc4a4dc938",
   "metadata": {},
   "source": [
    "#### Newton Rapshon-Shamaskii\n",
    "> Concetto chiave\n",
    "- La Jacobiana viene ***valutata ogni*** $m$ ***iterazioni***."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2235663-ca6f-4a21-9d88-068b28ab7203",
   "metadata": {},
   "outputs": [],
   "source": [
    "def newton_rapshon_sham(init_guess,f,J,tolx,tolf,nmax,counter):\n",
    "    X=np.array(init_guess)\n",
    "    \n",
    "    it=0\n",
    "    errorf=1+tolf\n",
    "    errorx=1+tolx\n",
    "    error=[]\n",
    "\n",
    "    while it<nmax and errorf>=tolf and errorx>=tolx:\n",
    "        \n",
    "        if it % counter == 0: # Calculate jx only once every \"counter\" steps\n",
    "            jx=J(X[0],X[1])\n",
    "        shamCounter=shamCounter + 1\n",
    "        \n",
    "        if np.linalg.det(jx)==0:\n",
    "            print(\"J-Matrix does not have max rank\")\n",
    "            return None,None,None\n",
    "        fx=np.array(f(X[0],X[1]))\n",
    "        fx=fx.squeeze()\n",
    "        \n",
    "        s=np.linalg.solve(jx,-fx)\n",
    "\n",
    "        Xnew=X+s\n",
    "        XnNorm=np.linalg.norm(Xnew,1)\n",
    "\n",
    "        if XnNorm!=0:\n",
    "            errorx=np.linalg.norm(s,1)/XnNorm\n",
    "        else:\n",
    "            errorx=np.linalg.norm(s,1)\n",
    "        error.append(errorx)\n",
    "        fnew=f(Xnew[0],Xnew[1])\n",
    "        errorf=np.linalg.norm(fnew.squeeze(),1)\n",
    "\n",
    "        X=Xnew\n",
    "        it=it+1\n",
    "    return X,it,error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9562c73-9110-4912-bb07-4f368d6d23bd",
   "metadata": {},
   "source": [
    "#### Minimum of Non Linear Function\n",
    "> Concetto Chiave\n",
    "\n",
    "Occorre esaminare la matrice Hessiana $H(X)$\n",
    "Il sistema riscritto in **termini matriciali** diventa:\n",
    "$$\n",
    "0=\\nabla f(X_{k})+H(X_{k})(X-X_{k})\n",
    "$$\n",
    "\n",
    "Sotto l'ipotesi che $\\det H(X_{k})\\neq0$ si ricava:\n",
    "$$\n",
    "X-X_{k}=-H^{-1}(X_{k})\\nabla f(X_{k})\n",
    "$$\n",
    "\n",
    "> Schematizzazione dell'algoritmo:\n",
    "1. Valutare $H(X_{k-1})$\n",
    "2. Risolvere il sistema lineare $ H(X_{k})s_{k}=-\\nabla f(X_{k})$\n",
    "3. Porre $X_k=X_{k-1}+s_{k-1}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cd58e9d1-0485-4870-8e48-7e439333af45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def newton_rapshon_min(init_guess,grad_f_num,H_num,tolx,tolf,nmax):\n",
    "    X=np.array(init_guess)\n",
    "    \n",
    "    it=0\n",
    "    errorf=1+tolf\n",
    "    errorx=1+tolx\n",
    "    error=[]\n",
    "\n",
    "    while it<nmax and errorf>=tolf and errorx>=tolx:\n",
    "        Hx=H_num(X[0],X[1])\n",
    "        if np.linalg.det(Hx)==0:\n",
    "            print(\"H-Matrix does not have max rank\")\n",
    "            return None,None,None\n",
    "        \n",
    "        gfx=grad_f_num(X[0], X[1])\n",
    "        gfx=gfx.squeeze()\n",
    "        \n",
    "        s=np.linalg.solve(Hx,-gfx)\n",
    "\n",
    "        Xnew=X+s\n",
    "        XnNorm=np.linalg.norm(Xnew,1)\n",
    "        \n",
    "        # Criteri di arresto\n",
    "        if XnNorm!=0:\n",
    "            errorx=np.linalg.norm(s,1)/XnNorm\n",
    "        else:\n",
    "            errorx=np.linalg.norm(s,1)\n",
    "\n",
    "        gradf_xnew=grad_f_num(Xnew[0],Xnew[1])\n",
    "        errorf=np.linalg.norm(gradf_xnew.squeeze(),1)\n",
    "        \n",
    "        error.append(errorx)\n",
    "\n",
    "        X=Xnew\n",
    "        it=it+1\n",
    "    return X,it,error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91133e05-def7-479b-9898-32594e916d72",
   "metadata": {},
   "source": [
    "### Linear Systems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a6c8c0b-da29-41f0-b645-bbf2e826a701",
   "metadata": {},
   "source": [
    "#### Iterative Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8da0246-d51a-4541-8547-b448f933d600",
   "metadata": {},
   "source": [
    "> Metodi che generano una ***successione di soluzioni*** che sotto *opportune ipotesi*, convergono alla **soluzione**.\n",
    "\n",
    "I metodi si basano tutti sullo stesso ***principio di decomposizione***.\n",
    "- Si decompone $A$ in due matrici tali che: $A=M-N$ con $\\det(M)\\neq 0$\n",
    "\n",
    "$$(M-N)x=b\\implies Mx=Nx +b$$\n",
    "Il metodo suggerisce le soluzioni successive:\n",
    "$$x^{(k)}=M^{-1}Nx^{(k-1)}+M^{-1}b\\quad k=1,2,\\dots$$\n",
    "\n",
    "> Si parte da un vettore $x^{(0)}$ arbitrario e si costruisce la soluzione tramite il processo iterativo:\n",
    "\n",
    "$$x^{(k)}=Tx^{(k-1)}+q\\qquad k=1,2,\\dots$$\n",
    "**Dove** \n",
    "- $T=M^{-1}N$ è detta ***matrice di iterazione*** del metodo iterativo.\n",
    "- $q=M^{-1}b$\n",
    "\n",
    "Nei prossimi metodi si considera la seguente decomposizione:\n",
    "$$A=D+E+F$$\n",
    "$$\n",
    "D=\\begin{bmatrix}\n",
    "a_{11} &  \\\\\n",
    " & \\ddots \\\\\n",
    "&  & a_{nn}\n",
    "\\end{bmatrix},\n",
    "E=\\begin{bmatrix}\n",
    "0 & 0 & \\dots & 0 & 0 \\\\\n",
    "a_{21} & 0  & \\dots & 0 & 0\\\\\n",
    "a_{31} &  a_{32} &  \\ddots & 0 & 0 \\\\\n",
    "\\vdots  & \\vdots & \\ddots & \\ddots & \\vdots\\\\\n",
    "a_{n1} & a_{n2} &  \\dots& a_{nn-1} & 0\n",
    "\\end{bmatrix},\n",
    "F=\\begin{bmatrix}\n",
    "0 & a_{12} & a_{13} & \\dots & a_{1n} \\\\\n",
    "0 & 0 & a_{23} & \\dots & a_{2n} \\\\\n",
    "\\vdots & \\vdots & \\ddots & \\ddots & \\vdots \\\\\n",
    "0 & 0 & 0 & \\ddots & a_{n-1n} \\\\\n",
    "0 & 0 & 0 & \\dots & 0\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "- $D$ Matrice *diagonale*\n",
    "- $E$ Matrice *Triangolare Inferiore*\n",
    "- $F$ Matrice *Triangolare Superiore*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb54f550-7bad-4db2-8af9-943a8390528b",
   "metadata": {},
   "source": [
    "###### Teorema Convergenza\n",
    "La condizione ***necessaria e sufficiente*** per la *convergenza* del procedimento iterativo, comunque si scelga il vettore iniziale $x^{(0)}$, al vettore soluzione $x$ del sistema $Ax=b$ , è che:\n",
    ">$$\\rho(T)<1$$\n",
    "\n",
    "Più il raggio spettrale è *piccolo* più è **veloce la convergenza**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb91374-1121-443e-962e-2eaea777e2f5",
   "metadata": {},
   "source": [
    "##### Jacobi\n",
    "> Nel metodo di Jacobi la *decomposizione* di $A$ nella forma $A=M-N$ si ottiene scegliendo $M=D$ e $N=-(E+F)$\n",
    "\n",
    "Il procedimento iterativo diventa:\n",
    "$$x^{(k)}=-D^{-1}(E+F)x^{(k-1)}+D^{-1}b_{1}\\quad k=1,2,\\dots$$\n",
    "- Raccogliendo $D^{-1}$\n",
    "$$x^{k}=D^{-1}(\\underbrace{ N }_{ -(E+F) }x^{(k-1)}+b)$$\n",
    "\n",
    "Ogni elemento dell'iterato $(k)$ è ***indipendente dagli altri***:\n",
    "- Ottimo metodo per la parallelizzazione."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c5ea10c5-f730-4f08-bb21-f26d4be0ea07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def jacobi(A,b,x0,toll,it_max):\n",
    "    errore=1000\n",
    "    d=np.diag(A)\n",
    "    n=A.shape[0]\n",
    "    E=np.tril(A,-1)\n",
    "    F=np.triu(A,1)\n",
    "    N=-(E+F)\n",
    "\n",
    "    # Convergencee Check (||T|| < 1 or sr < 1)\n",
    "    T=np.dot(np.diag(1/d),N)\n",
    "    eigenvalues=np.linalg.eigvals(T)\n",
    "    spectralradius=np.max(np.abs(eigenvalues)) # sprad < 1 -> Converge\n",
    "    # print(\"Norm:\",np.linalg.norm(T,2))\n",
    "    \n",
    "    it=0\n",
    "    er_vet=[]\n",
    "    while it<=it_max and errore>=toll:\n",
    "        x=(b+N@x0)/d.reshape(n,1)\n",
    "        errore=np.linalg.norm(x-x0)/np.linalg.norm(x)\n",
    "        er_vet.append(errore)\n",
    "        x0=x.copy()\n",
    "        it=it+1\n",
    "    return x,it,er_vet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce426e9-9a51-4123-a8b7-1f569741aa0b",
   "metadata": {},
   "source": [
    "##### Gauss Seidel\n",
    "> La *decomposizione* di $A$ si ottiene scegliendo $M=E+D$ e $N=-F$\n",
    "\n",
    "La soluzione al passo $k$ si ottiene come:\n",
    "$$x^{(k)}=-(E+D)^{-1}Fx^{(k-1)}+(E+D)^{-1}b\\quad k=1,2,\\dots$$\n",
    "\n",
    "In termini di componenti:\n",
    "$$Mx^{(k)}=Nx^{(k-1)}+b$$\n",
    "\n",
    "Sostituendo ad $M$ la matrice $E+D$ e ad $N$ la matrice $-F$, otteniamo:\n",
    "$$\n",
    "\\begin{array}\n",
    "\\ (E + D)\\,x^{(k)} = -F\\,x^{(k-1)} + b \\qquad k = 1, 2, \\dots \\\\\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "- Questo passaggio suggerisce che la soluzione al passo $(k)$ si ottiene risolvendo il sistema ***triangolare inferiore*** avente $(E+D)$ come matrici dei coefficienti e termine noto $b-Fx^{(k-1)}$.\n",
    "$$Mx^{(k)}=b+Nx^{(k-1)}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ed313563-de3c-406b-8dff-75f8d13a3d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gauss_seidel(A,b,x0,toll,it_max):\n",
    "    errore=1000\n",
    "    d=np.diag(A)\n",
    "    D=np.diag(d)\n",
    "    E=np.tril(A,-1)\n",
    "    F=np.triu(A,1)\n",
    "    M=D+E\n",
    "    N=-F\n",
    "\n",
    "    # Convergence check\n",
    "    invM=np.linalg.inv(M)\n",
    "    T=invM@N\n",
    "    eigenvalues=np.linalg.eigvals(T)\n",
    "    spectralradius=np.max(np.abs(eigenvalues))\n",
    "    # print(\"raggio spettrale Gauss-Seidel \",raggiospettrale)\n",
    "\n",
    "    # print(\"Norm:\", np.linalg.norm(T,2))\n",
    "    \n",
    "    it=0\n",
    "    er_vet=[]\n",
    "    while it<=it_max and errore>=toll:\n",
    "        x,flag=st.Lsolve(M,b+N@x0) # Key Operation\n",
    "        errore=np.linalg.norm(x-x0)/np.linalg.norm(x)\n",
    "        er_vet.append(errore)\n",
    "        x0=x.copy()\n",
    "        it=it+1\n",
    "    return x,it,er_vet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "813c06ed-24d5-4dcd-b2da-f85203cc94ad",
   "metadata": {},
   "source": [
    "##### Gauss Seidel SOR\n",
    "> Accelerazione di un Metodo Iterativo\n",
    "\n",
    "Partendo dal metodo di **Gauss Seidel**:\n",
    "$$\n",
    "x^{(k)} = -D^{-1}(E\\,x^{(k)} + F\\,x^{(k-1)} - b)\n",
    "$$\n",
    "Può essere riscritto nella forma:\n",
    "- $x^{(k)}=x^{(k-1)}+r^{(k)}$\n",
    "\n",
    "*Dove*\n",
    "$$\n",
    "r^{(k)}=x^{(k)}-x^{(k-1)}=-D^{-1}[Ex^{(k)}+Fx^{(k-1)}-b]-x^{(k-1)}\n",
    "$$\n",
    "\n",
    "> Modificando il *metodo di Gauss-Seidel* otteniamo:\n",
    "\n",
    "$$\n",
    "x^{(k)}=x^{(k-1)}+\\omega r^{(k)}\n",
    "$$\n",
    "\n",
    "Scegliendo opportunamente il parametro $\\omega>0$ si può ***accelerare la convergenza in modo significativo***.\n",
    "\n",
    "Il metodo **SOR** si ottiene sostituendo (1) con (2):\n",
    "$$x^{(k)} = (1 - \\omega)x^{(k-1)} - \\omega D^{-1}[E x^{(k)} + F x^{(k-1)} - b]$$\n",
    "\n",
    "Da cui si ricava:\n",
    "\n",
    "$$x^{(k)} = (1 - \\omega)x^{(k-1)} + \\omega[-D^{-1}[E x^{(k)} + F x^{(k-1)} - b]]$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8f1837dd-e90f-49e4-b9a4-72e5450ec974",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gauss_seidel_sor(A,b,x0,toll,it_max,omega):\n",
    "    errore=1000\n",
    "    d=np.diag(A)\n",
    "    D=np.diag(d)\n",
    "    Dinv=np.diag(1/d)\n",
    "    E=np.tril(A,-1)\n",
    "    F=np.triu(A,1)\n",
    "\n",
    "    # Iteration Matrix\n",
    "    Momega=D+omega*E\n",
    "    Nomega=(1-omega)*D-omega*F\n",
    "    T=np.dot(np.linalg.inv(Momega),Nomega)\n",
    "\n",
    "    # Convergence Check\n",
    "    eigenvalues=np.linalg.eigvals(T)\n",
    "    spectralradius=np.max(np.abs(eigenvalues))\n",
    "    # print(\"raggio spettrale Gauss-Seidel SOR \", raggiospettrale)\n",
    "    \n",
    "    M=D+E\n",
    "    N=-F\n",
    "    it=0\n",
    "    xold=x0.copy()\n",
    "    xnew=x0.copy()\n",
    "    er_vet=[]\n",
    "    while it<=it_max and errore>=toll:\n",
    "        xtilde,flag=Lsolve(M, b-F@xold)\n",
    "        xnew=(1-omega)*xold+omega*xtilde\n",
    "        errore=np.linalg.norm(xnew-xold)/np.linalg.norm(xnew)\n",
    "        er_vet.append(errore)\n",
    "        xold=xnew.copy()\n",
    "        it=it+1\n",
    "    return xnew,it,er_vet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c85656-45e0-4c99-a843-cbca35d67bd9",
   "metadata": {},
   "source": [
    "#### Direct Methods\n",
    "#####  Fattorizzazione\n",
    ">Obbiettivo\n",
    "\n",
    "L'obbiettivo della ***fattorizzazione*** $A=BC$ è quello di trasformare il sistema lineare $Ax=b$ in un sistema lineare *equivalente*.\n",
    "$$BCx=b$$\n",
    "- Si può spezzare in due problemi:\n",
    "$$\\begin{cases}By=b \\\\ Cx=y\\end{cases}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f24914e5-2f90-4747-b2cb-43a6179f7ae0",
   "metadata": {},
   "source": [
    "##### Stabilità di un Algoritmo di Fattorizzazione\n",
    "> Consideriamo la fattorizzazione $A=BC$\n",
    "\n",
    "Consideriamo:\n",
    "- $\\mathcal{B}=B+\\delta B$\n",
    "- $\\mathcal{C}=C+\\delta C$\n",
    "\n",
    ">I fattori $\\mathcal{B},\\mathcal{C}$ possono essere pensati come fattorizzazione esatta di una *matrice perturbata*.\n",
    "\n",
    "$$\n",
    "A+\\delta A=\\mathcal{B}\\cdot\\mathcal{C}\n",
    "$$\n",
    "Quindi\n",
    "$$\n",
    "A+\\delta A=\\underbrace{ (B+\\delta B)\\cdot(C+\\delta C) }_{ BC+B\\delta C+\\delta BC+\\delta B\\delta C }\n",
    "$$\n",
    "La relazione non dipende solo dalle perturbazioni, ma è tanto più grande quanto sono più grandi gli elementi dei fattori $B$ e $C$.\n",
    "\n",
    "###### Stabilità di un Algoritmo di Fattorizzazione\n",
    ">Data una matrice $A$ i cui elementi sono tutti minori o uguali a $1$, si dice che un *algoritmo di fattorizzazione* è ***numericamente stabile in senso forte***, se esistono delle costanti positive $a$ e $b$ indipendenti dall'ordine e dagli elementi di $A$ tali che:\n",
    ">$$\\mid b_{ij}\\mid\\leq a\\quad \\mid c_{ij}\\mid\\leq b$$\n",
    "\n",
    "Se le costanti $a,b$ dipendono dall'ordine di $A$ si dice che la fattorizzazione è ***stabile in senso debole***."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc1f228-a86b-48f5-809f-846a2361601e",
   "metadata": {},
   "source": [
    "##### Gauss with Pivot\n",
    "> Il metodo di eliminazione Gaussiana si basa sulla fattorizzazione $A=LU$\n",
    "\n",
    "> Teorema\n",
    "\n",
    "Data $A\\in\\mathbb{R}^{n\\times n}$ sia $A_{k}$ la sottomatrice principale di testa di $A$ considerando le prime $k$ righe e colonne di $A$.\n",
    "Se $A_{k}$ ***non è singolare*** per ogni $k=1,\\dots,n-1$ allora esiste ed è unica la fattorizzazione $LU$ di $A$\n",
    "\n",
    "Dove:\n",
    "- $L$ è una matrice **triangolare inferiore**.\n",
    "- $U$ è una matrice **triangolare superiore**.\n",
    "\n",
    "Data una qualunque matrice $A$ non singolare, esiste una matrice di permutazione $P$ non singolare t.c. $PA=LU$\n",
    "- Una ***matrice di permutazione*** è una matrice ottenuta dalla *matrice identità* **scambiando** due righe tra di loro. Effettuare $P\\cdot A$ equivale a scambiare le stesse due righe della matrice $A$.\n",
    "- La **matrice di permutazione** è sempre una matrice ortogonale, cioè: $PP^T=I$\n",
    "\n",
    "> Gauss con Pivotaggio\n",
    "\n",
    "Al passo $k$, prima di calcolare $l_{ik}$, se $a_{kk}=0$ si cerca dalla colonna $k$-*esima* a partire dalla riga $k$-*esima*, la posizione di riga $s$ in cui si trova il ***primo elemento diverso da zero***.\n",
    "\n",
    "Sfruttando questo concetto la soluzione del sistema diventa:\n",
    "$$\n",
    "\\begin{cases}\n",
    "Ly=P\\cdot b \\\\\n",
    "Ux=y\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "> Algoritmo ***Stabile in Senso Debole***\n",
    "\n",
    "$$|l_{ij}|\\leq 1\\qquad \\mid u_{ij}\\mid\\leq 2^{n-1}\\max\\mid a_{ij}\\mid$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "df910b76-0ca1-41a9-9021-3f747a18595e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LUsolve(A,b):\n",
    "    PT,L,U=sp.linalg.lu(A) #Returns P,L,B : A=P@L@U => P.T@A=L@U\n",
    "    P=PT.T.copy()\n",
    "    y,flag=st.Lsolve(L,P@b)\n",
    "    if flag==0:\n",
    "        x,flag=st.Usolve(U,y)\n",
    "        if flag!=0:\n",
    "            return [],flag\n",
    "    else:\n",
    "        return [],flag\n",
    "    return x,flag"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8900425-c39d-4e16-8c3b-ad8eb8468931",
   "metadata": {},
   "source": [
    "##### Householder Method ($QR$)\n",
    "Se $A\\in\\mathbb{R}^{m\\times n}$, con $m\\geq n$ e $\\text{rank}(A)=n$.\n",
    "***Allora***\n",
    "Esistono una matrice $Q\\in\\mathbb{R}^{m\\times m}$ **ortogonale** e una matrice $R=\\begin{pmatrix}R_{1} \\\\ 0\\end{pmatrix}\\in \\mathbb{R}^{(m-n)\\times n}$ dove $R_{1}\\in\\mathbb{R}^{n\\times n}$, è una matrice triangolare superiore ***non singolare***, e $0\\in \\mathbb{R}^{(m-n)\\times n}$ è una matrice di zeri tali che $A=QR$ \n",
    "\n",
    "Usando questa **fattorizzazione** la soluzione si riduce a:\n",
    "$$\n",
    "\\begin{cases}\n",
    "Qy=b \\implies y=Q^Tb\\\\\n",
    "Rx=y\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "> Algoritmo ***stabile in senso debole***, ma più stabile di Gauss\n",
    "\n",
    "$$\\mid q_{ij}\\mid\\leq 1\\qquad \\mid r_{ij}\\mid\\leq \\sqrt{ n }\\max\\limits_{ij}\\mid a_{ij}\\mid$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d0e8679a-6a97-4b83-ba5f-125ca58a5a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def QRsolve(A,b):\n",
    "    Q,R=sp.linalg.qr(A)\n",
    "    y=Q.T@b\n",
    "    x,flag=st.Usolve(R,y)\n",
    "    if flag != 0:\n",
    "        return [], flag\n",
    "    else:\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "357e87dd-0e96-4e48-9fb5-feb0342955ae",
   "metadata": {},
   "source": [
    "##### Cholesky"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e79d4fd-043d-493b-9799-44bb6890a2f4",
   "metadata": {},
   "source": [
    "> Solo per matrici simmetriche e definite positive\n",
    "\n",
    "Esiste una matrice triangolare inferiore $L$ con elementi *diagonali positivi*. ($l_{ii}>0,i=1,\\dots,n$) tale che:\n",
    "$$A=L\\cdot L^T$$\n",
    "\n",
    "La soluzione si riduce a:\n",
    "$$\n",
    "\\begin{cases}\n",
    "Ly=b \\\\\n",
    "L^Tx=y\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "> Algoritmo ***Stabile in senso Forte***\n",
    "\n",
    "$$\\max\\limits_{ij}\\mid l_{ij}\\mid\\leq\\sqrt{ \\max\\limits_{ij}\\mid a_{ij}\\mid }$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2607b151-2bc2-4937-a1aa-75f1caa0894a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_cholesky(A,b):\n",
    "    if is_positively_defined(A) and is_symmetric(A):\n",
    "        L=sp.linalg.cholesky(A,lower=True)\n",
    "        y,flag=st.Lsolve(L,b)\n",
    "        x,flag=st.Usolve(L.T,y)\n",
    "        return x\n",
    "    else:\n",
    "        print('Matrix does not meet requirements')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f9ce692-872b-47c4-9114-2a7e03bc3e7a",
   "metadata": {},
   "source": [
    "#### Overdetermined Systems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9534e798-00e1-44ec-84d9-a00c449d9ad3",
   "metadata": {},
   "source": [
    "##### Normal Equations\n",
    "Definiamo il vettore residuo come:\n",
    "$$r(x):=Ax-b$$\n",
    "Cerchiamo il vettore $x^* \\in \\mathbb{R}^n$ che rende minima la norma 2 al ***quadrato del residuo***.\n",
    "$$x^*=\\arg\\min\\limits_{x\\in\\mathbb{R}^n }\\|Ax-b\\|_{2}^2=x^TA^TAX-2x^TA^Tb+b^Tb$$\n",
    "- Poniamo $G=A^TA$\n",
    "\n",
    "> Poichè $G$ è **Matrice Simmetrica** e **Definita Positiva** possiamo usare la fattorizzazione di Cholesky.\n",
    "\n",
    "$$F(x)=x^TGx-2x^TA^Tb+b^Tb$$\n",
    "\n",
    "Per calcolare il valore di $x^*$ che rende minimo $F(x)$ calcoliamo il gradiente di $F(x)$ e *poniamo che si annulli*.\n",
    "$$\\nabla F(x)=2Gx-2A^Tb=0$$\n",
    "\n",
    "Il vettore $x^*$ che annulla il gradiente della funzione $F(x)$ è la soluzione del sistema lineare:\n",
    "$$Gx=A^Tb$$\n",
    "\n",
    "> Teorema\n",
    "\n",
    "Dato il ***sistema lineare sovradeterminato*** $Ax=b$ dove $A\\in\\mathbb{R}^{m\\times n},\\quad x\\in\\mathbb{R}^n, \\quad b\\in\\mathbb{R}^m,\\quad m>n$\n",
    "$\\arg\\min\\limits_{x\\in\\mathbb{R}^n }\\|Ax-b\\|_{2}^2\\iff$ è la *soluzione* di $A^TAx=A^Tb$\n",
    "- La soluzione è unica se e solo se la matrice $A$ ha ***rango massimo***\n",
    "\n",
    "> Condizionamento:\n",
    "$$K_{2}(A^TA)=(K_{2}(A))^2$$\n",
    "\n",
    "Se il problema è mediamente mal condizionato, il metodo è **numericamente pericoloso**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7424e7c3-7db7-4827-a669-8182c6d61ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eqnorm(A,b):\n",
    "    G=A.T@A\n",
    "    \n",
    "    print(\"Condition Number of G: \", np.linalg.cond(G))\n",
    "\n",
    "    f=A.T@b\n",
    "\n",
    "    L=sp.linalg.cholesky(G,lower=True)\n",
    "    U=L.T\n",
    "\n",
    "    z,flag=Lsolve(L,f)\n",
    "\n",
    "    if flag==0:\n",
    "        x,flag=Usolve(U,z)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77077daf-4bab-44b1-ad01-b20ca962ce28",
   "metadata": {},
   "source": [
    "##### QR Least Squares\n",
    "> Una volta calcolata la fattorizzazione $QR$ di una matrice $A$.\n",
    "\n",
    "Considerando che il prodotto di un vettore per una matrice ortogonale ***mantiene la norma euclidea***.\n",
    "$$\\|Q^T(Ax-b)\\|_{2}^2=\\|Q^TAx-Q^Tb\\|_{2}^2=\\|R_{1}x-Q^Tb\\|_{2}^2$$\n",
    "\n",
    "Posto $h=Q^Tb=\\begin{bmatrix}\\underbrace{ h_{1} }_{ n \\text{ componenti} }\\\\ \\underbrace{ h_{2} }_{ m-n \\text{ componenti}}\\end{bmatrix}$\n",
    "\n",
    "Quindi si ha che il minimo sarà ottenuto per $x^*$ che risolve il sistema lineare $R_1x=h_1$\n",
    "\n",
    "> Stabilità\n",
    "\n",
    "1. Si lavora **sempre** solo sulla matrice $A$, senza passare da $A^TA$\n",
    "2. La fattorizzazione $QR$ è *abbastanza stabile*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b9cf75c-903b-458d-af76-03f5a1d5378b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def qrLS(A,b):\n",
    "    n=A.shape[1]\n",
    "    Q,R=sp.linalg.qr(A)\n",
    "    \n",
    "    h=Q.T@b\n",
    "    \n",
    "    x, flag =st.Usolve(R[:n,:],h[:n])\n",
    "    r=np.linalg.norm(h[n:])\n",
    "    return x,r"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada1ac7e-7865-4af3-b88d-e6b661896267",
   "metadata": {},
   "source": [
    "##### Singular Value Decomposition Least Squares\n",
    "Sia $A\\in\\mathbb{R}^{m\\times n}$ a rango $k\\leq\\min(m,n)$, allora esistono due **matrici ortogonali** $U\\in\\mathbb{R}^{m\\times n}$ e $V\\in\\mathbb{R}^{m\\times n}$ tali che:\n",
    "$$U^TAV=\\Sigma=diag(\\sigma_{1},\\sigma_{2},\\dots,\\sigma_{k},0,\\dots,0)$$\n",
    "\n",
    "I valori della diagonale $\\sigma$ sono detti valori singolari di $A$ e soddisfano:\n",
    "$$\\sigma_{1}\\geq \\sigma_{2}\\geq\\dots\\geq\\sigma_{k}\\geq0$$\n",
    "\n",
    "Il rapporto $\\displaystyle\\frac{\\sigma_{\\max}}{\\sigma_{\\min}}$ ci fornisce l'***indice di condizionamento*** della *matrice* $A$.\n",
    "\n",
    "> Bisogna aggiungere una condizione sulla soluzione cercata:\n",
    "\n",
    "$$\\|Ax-b\\|_{2}^2=\\|U^T(Ax-b)\\|_{2}^2=\\|U^TAVV^Tx-U^Tb\\|_{2}^2=\\|\\Sigma V^Tx-U^Tb\\|_{2}^2$$\n",
    "- $c=V^Tx$\n",
    "- $d=U^Tb$\n",
    "\n",
    "\n",
    "$$\\underset{ x\\in\\mathbb{R}^n }{ \\arg\\min }\\|Ax-b\\|_{2}^2=\\underset{ c\\in\\mathbb{R}^n }{ \\arg\\min }\\|\\Sigma c-d_{1}\\|_{2}^2+\\|d_{2}\\|_{2}^2$$\n",
    "Per rendere minimo il residuo:\n",
    "- Si deve *annullare* $\\Sigma c-d_{i} \\implies \\Sigma c=d_i$\n",
    "\n",
    "Poniamo quindi $c_i=0$ per $i=k+1,\\dots,n$ che rappresenta una condizione aggiuntiva per ottenere la **soluzione di minima norma**.\n",
    "\n",
    "La soluzione del sistema diventa quindi:\n",
    "$$x=Vc=\\sum_{i=1}^kc_{i}v_{i}$$\n",
    "\n",
    "- dove $v_{i}, i=1,\\dots,n$ indicano le *colonne* della matrice $V$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "efeae69a-3c5b-42be-84e5-c0326e9c1d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SVDLS(A,b):\n",
    "    m,n=A.shape  #numero di righe e  numero di colonne di A\n",
    "    U,s,VT=spLin.svd(A)  \n",
    "    \n",
    "    V=VT.T\n",
    "    thresh=np.spacing(1)*m*s[0] ##Calcolo del rango della matrice, numero dei valori singolari maggiori di una soglia\n",
    "    k=np.count_nonzero(s>thresh)\n",
    "    \n",
    "    d=U.T@b\n",
    "    d1=d[:k].reshape(k,1) # Seleziono i primi k elementi di d\n",
    "    s1=s[:k].reshape(k,1) # Seleziono i primi k elementi di s\n",
    "    \n",
    "    c=d1/s1\n",
    "    x=V[:,:k]@c\n",
    "    r=np.linalg.norm(d[k:])**2 \n",
    "    return x,r"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1d5c46-db02-4226-95a8-e0c13b7ef70b",
   "metadata": {},
   "source": [
    "## Descent Methods\n",
    "---\n",
    "> Concetti Generali\n",
    "\n",
    "Sia $A\\in\\mathbb{R}^{n\\times n}$, matrice *simmetrica* e *definita positiva*, $b,x\\in\\mathbb{R}^n$\n",
    "<u>Allora</u>\n",
    "La soluzione del sistema lineare $Ax=b$ coincide con il punto di minimo della seguente ***funzione quadratica***.\n",
    "$$F(x)=\\frac{1}{2}<Ax,x> - <b,x> =\\frac{1}{2}x^TAx-b^Tx=\\frac{1}{2}\\sum_{i=1}^n\\sum_{j=1}^na_{ij}x_{i}x_{j}-\\sum_{i=1}^nb_{i}x_{i}$$\n",
    "Dove la forma quadratica $Q(x)= <Ax,x\\geq x^TAx$ è positiva per $x\\neq0$\n",
    "\n",
    ">Il teorema afferma che il vettore che risolve il sistema lineare coincide con il vettore che ***minimizza la forma quadratica***.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef87214-f9c5-4147-8602-5169e45d815f",
   "metadata": {},
   "source": [
    "### Steepest Descent\n",
    "> Caratterizzato dalla scelta ad ogni passo $k$ , della direzione $p^{(k)}$ come l'***antigradiente*** della funzione $F$ calcolato nell'iterato $k$-esimo:\n",
    "\n",
    "$$p^{(k)}=-\\nabla F(x^{(k)})=-Ax^{(k)}+b=-r^{(k)}$$\n",
    "\n",
    "> Passaggi Iterativi:\n",
    "\n",
    "1. Determina la direzione $p^{(k)}$\n",
    "2. Scegli lo Step-Size $\\alpha^{(k)}=-\\displaystyle{\\frac{<r^{(k)},p^{(k)}>}{<Ap^{(k)},p^{(k)}>}}$\n",
    "3. Aggiorna l'iterato $x^{(k+1)}=x^{(k)}+\\alpha^{(k)}p^{(k)}$\n",
    "4. Aggiorna il residuo $r^{(k+1)}=r^{(k)}+\\alpha Ap$\n",
    "\n",
    "> Ordine di Convergenza\n",
    "\n",
    "Il metodo ha ordine di convergenza lineare con fattore:\n",
    "$$\\rho=\\displaystyle{\\frac{K(A)-1}{K(A)+1}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c7eeb66a-9dd7-4055-867f-78799b68e2d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def steepestdescent(A,b,x0,itmax,tol):\n",
    "    x=x0.copy()\n",
    "    r=A@x-b\n",
    "    it=0\n",
    "    p=-r\n",
    "    normb=np.linalg.norm(b)\n",
    "\n",
    "    error=np.linalg.norm(r)/normb\n",
    "\n",
    "    vec_sol=[]\n",
    "    vec_sol.append(x.copy())\n",
    "    vec_r=[]\n",
    "    vec_r.append(error)\n",
    "\n",
    "    while error>=tol and it<itmax:\n",
    "        it=it+1\n",
    "        \n",
    "        Ap=A@p\n",
    "        alpha=(r.T@r)/(p.T@Ap)\n",
    "        \n",
    "        x=x+alpha*p\n",
    "        r=r+alpha*Ap\n",
    "\n",
    "        vec_sol.append(x.copy())\n",
    "        error=np.linalg.norm(r)/normb\n",
    "        vec_r.append(error)\n",
    "        p=-r # Max descent (Opposite of gradient)\n",
    "        \n",
    "    iterates=np.vstack([arr.T for arr in vec_sol]) # Only for graphical purpose\n",
    "\n",
    "    return x,vec_r, iterates, it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "180f78a8-a628-475a-87ec-a3e23f94fd62",
   "metadata": {},
   "source": [
    "#### Conjugate Gradient\n",
    "> Si sceglie la **nuova direzione di discesa** come quella *appartenente al piano* $\\pi_{k}$ passante per $x^{(k)}$e individuato da $r^{(k)}$ e $p^{(k-1)}$.\n",
    "\n",
    "$$p^{(k)}=-r^{(k)}+\\gamma_{k}p^{(k-1)}\\qquad k=1,2,\\dots$$\n",
    "\n",
    "- $\\gamma$ è scelto in modo che la direzione $p$ punti verso il *centro dell'ellisse*.\n",
    "\n",
    "Scegliamo $\\gamma$ come:\n",
    "$$\\gamma^{(k)}=\\displaystyle{\\frac{<r^{(k)},r^{(k)}>}{<r^{(k-1)},r^{(k-1)}>}}$$\n",
    "\n",
    "- Molto efficiente poichè il calcolo $<r^{(k-1)},r^{(k-1)}>$ è già stato fatto per calcolare lo step size.\n",
    "  \n",
    "\n",
    "\n",
    "> Ordine di Convergenza\n",
    "\n",
    "Il metodo ha Ordine di Convergenza lineare con fattore:\n",
    "$$\\rho=\\displaystyle{\\frac{\\sqrt{ K(A) }-1}{\\sqrt{ K(A) }+1}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1d0fc4b6-fb04-4d1c-b5c0-236f70050c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conjugateGradient(A,b,x0,itmax,tol):\n",
    "    \n",
    "    x=x0.copy()\n",
    "    r=A@x-b\n",
    "    p=-r\n",
    "    it=0\n",
    "    errore=np.linalg.norm(r)/np.linalg.norm(b)\n",
    "    \n",
    "    vec_sol=[]\n",
    "    vec_sol.append(x.copy())\n",
    "    vec_r=[]\n",
    "    vec_r.append(errore)\n",
    "\n",
    "    while errore>=tol and it<itmax:\n",
    "        it=it+1\n",
    "        \n",
    "        Ap=A@p\n",
    "\n",
    "        save=(r.T@r)\n",
    "        alpha=save/(Ap.T@p)\n",
    "        \n",
    "        x=x+alpha*p\n",
    "        r=r+alpha*Ap\n",
    "\n",
    "        vec_sol.append(x.copy())\n",
    "        errore=np.linalg.norm(r)/normb\n",
    "        vec_r.append(errore)\n",
    "\n",
    "        gamma=(r.T@r)/save\n",
    "        p=-r+gamma*p # Max descent (Opposite of gradient)\n",
    "        \n",
    "    iterates=np.vstack([arr.T for arr in vec_sol]) # Only for graphical purpose\n",
    "\n",
    "    return x,vec_r, iterates, it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c1b35a-b4f8-4741-b2b9-7da1f2869a84",
   "metadata": {},
   "source": [
    "## Interpolation\n",
    "---\n",
    "Note le coppie (**nodi**) $(x_{i},y_{i})$ con $i=0,\\dots,n$ e $x_{i}\\neq x_{k}\\quad i\\neq k$ e $y_{i}$ il problema dell'***interpolazione polimoniale*** consiste nell'individuare i coefficienti $\\alpha_{i}$ del polinomio $P_{n}(x)$ tale che sia soddisfatta la ***condizione di interpolazione***.\n",
    "$$P_{n}(x_{i})=y_{i}$$\n",
    "\n",
    "$P_{n}(x_{i})=y_{i}$ significa imporre:\n",
    "$$P_{n}(x_{i})= \\alpha_{0}+\\alpha_{1}x_{i}+\\alpha_{2}x_{i}^2+\\dots+\\alpha_{n}x_{i}^n=y_{i}$$\n",
    "\n",
    "Se scriviamo questa relazione per ogni $i$, ricaviamo il seguente sistema lineare:\n",
    "$$\n",
    "\\begin{cases}\n",
    "\\alpha_{0}+\\alpha_{1}x_{0}+\\alpha_{2}x_{0}+\\dots+\\alpha_{n}x_{0}^n=y_{0} \\\\\n",
    "\\alpha_{1}+\\alpha_{1}x_{1}+\\alpha_{2}x_{1}+\\dots+\\alpha_{n}x_{1}^n=y_{1} \\\\\n",
    "\\dots \\\\\n",
    "\\alpha_{n}+\\alpha_{1}x_{n}+\\alpha_{2}x_{n}+\\dots+\\alpha_{n}x_{n}^n=y_{n} \\\\\n",
    "\\end{cases}\n",
    "$$\n",
    "Dove la matrice dei coefficienti $A$ del sistema è la matrice di dimensione $(n+1)\\times(n+1)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db2f25e-2b0a-47fe-a711-e88a2b1dbe8b",
   "metadata": {},
   "source": [
    "### Lagrange Polynome\n",
    "> Cambiamento necessario per via del mal condizionamento della matrice costruita con la base canonica dello spazio vettoriale dei polinomi\n",
    "\n",
    "Gli $n+1$ ***polinomi di Lagrange***, $L_{j}^{(n)}$ sono polinomi di grado $n$ che rappresentano una base per lo spazio dei polinomi $\\mathbb{P}_{n}[x]$ e *soddisfano le condizioni*:\n",
    "$$\n",
    "L_{j}^{(n)}(x_{i})=\\begin{cases}\n",
    "1\\qquad \\text{se }i=0 \\\\\n",
    "0\\qquad \\text{se }i\\neq0\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "Sarà quindi della forma:\n",
    "$$L_{j}^{(n)}(x)=c(x-x_{0})(x-x_{1})\\dots(x-x_{j-1})(x-x_{j+1})\\dots(x-x_{n})$$\n",
    "\n",
    "> Determiniamo $c$ in maniera tale che $L_{j}^{(n)}(x_{j})=1$\n",
    "\n",
    "*Impongo*:\n",
    "$$\n",
    "L_{j}^{(n)}(x_{j})=c\\prod_{\\begin{array}\\ k=0 \\\\ k\\neq j\\end{array}}^{n}(x_{j}-x_{k})=1\n",
    "$$\n",
    "***Quindi***:\n",
    "$$\n",
    "L_{j}^{(n)}(x)=\\prod_{\\begin{array}\\ k=0 \\\\ k\\neq j\\end{array}}^{n} \\frac{(x-x_{k})}{(x_{j}-x_{k})}\n",
    "$$\n",
    "\n",
    "> Ricorda:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e1ba1ed9-934d-4f6d-915d-303f289ef699",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.poly(zeros)\n",
    "# Ritorna i coefficienti del polinomio che si annulla nei punti dati\n",
    "# np.polyval(coeff,val)\n",
    "# Ritorna la valutazione del polinomio con i coefficienti coeff nel valore val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd438d7-ca99-4f84-9821-792595523b93",
   "metadata": {},
   "source": [
    "### Interpolation With Lagrange Polynome\n",
    "Il polinomio $P_{n}(x)=\\alpha_{0}L_{0}^{(n)}(x)+\\alpha_{1}L_{1}^{(n)}(x)+\\dots+\\alpha_{n}L_{n}^{(n)}(x)$.\n",
    "- Imponendo le ***condizioni di interpolazione***, ricaveremo il seguente sistema lineare:\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "L_0^{(n)}(x_0) & L_1^{(n)}(x_0) & \\dots & L_n^{(n)}(x_0) \\\\\n",
    "L_0^{(n)}(x_1) & L_1^{(n)}(x_1) & \\dots & L_n^{(n)}(x_1) \\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "L_0^{(n)}(x_n) & L_1^{(n)}(x_n) & \\dots & L_n^{(n)}(x_n)\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "\\alpha_0 \\\\\n",
    "\\alpha_1 \\\\\n",
    "\\vdots \\\\\n",
    "\\alpha_n\n",
    "\\end{bmatrix}\n",
    "=\\begin{bmatrix}\n",
    "y_0 \\\\\n",
    "y_1 \\\\\n",
    "\\vdots \\\\\n",
    "y_n\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Che per la proprietà dei ***polinomi base di Lagrange*** si riduce a:\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "1 & 0 & \\dots & 0 \\\\\n",
    "0 & 1 & \\dots & 0 \\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "0 & 0 & \\dots & 1\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "\\alpha_0 \\\\\n",
    "\\alpha_1 \\\\\n",
    "\\vdots \\\\\n",
    "\\alpha_n\n",
    "\\end{bmatrix}=\\begin{bmatrix}\n",
    "y_0 \\\\\n",
    "y_1 \\\\\n",
    "\\vdots \\\\\n",
    "y_n\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0f710a85-43e7-46ba-9eca-f10946278c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plagr(nodes,j):\n",
    "    n=nodes.size\n",
    "    zeros=np.zeros_like(nodes)\n",
    "    \n",
    "    zeros=np.append(nodes[:j],nodes[j+1:]) # one-line based programming.\n",
    "\n",
    "    num=np.poly(zeros) # Per trovare il polinomio che si annulla in tutti i valori tranne il valore j\n",
    "    den=np.polyval(num,nodes[j]) # Per far sì che il polinomio trovato, dove non si annulla, valga 1\n",
    "\n",
    "    p=num/den # Trovo il Polinomio (!! Coefficienti del Polinomio !!)\n",
    "    \n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "04c4b2df-0be6-4db0-8686-423b55ccbce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def InterpL(x, y, xx):\n",
    "     \n",
    "    n=x.size\n",
    "    m=xv.size\n",
    "    L=np.zeros((m,n))\n",
    "    \n",
    "    for j in range(n):\n",
    "        p=plagr(x,j)\n",
    "        L[:,j]=np.polyval(p,xx)\n",
    "     \n",
    "    return L@y # Rappresenta il Polinomio"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
